---
phase: 03-ai-reliability
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/app/api/decompose/route.ts
  - src/components/workflow-input.tsx
  - src/lib/store.ts
  - src/app/page.tsx
autonomous: true

must_haves:
  truths:
    - "During AI analysis, the user sees server-driven progress messages that reflect actual processing stages, not time-based guesses"
    - "When Claude API errors are exhausted after retries, the user sees a specific error message (rate limit vs timeout vs connection) rather than a generic failure"
    - "When partial results are recovered, the user is navigated to the xray page with a warning indicator rather than seeing an error"
  artifacts:
    - path: "src/app/api/decompose/route.ts"
      provides: "SSE streaming decompose endpoint with progress events, typed error handling, partial result support"
      contains: "text/event-stream"
    - path: "src/components/workflow-input.tsx"
      provides: "SSE consumer that reads progress events and updates UI state"
      contains: "getReader"
    - path: "src/lib/store.ts"
      provides: "Zustand store with progressMessage state for decompose progress"
      contains: "progressMessage"
    - path: "src/app/page.tsx"
      provides: "Loading indicator driven by server progress messages instead of elapsed time"
      contains: "progressMessage"
  key_links:
    - from: "src/app/api/decompose/route.ts"
      to: "src/lib/claude.ts"
      via: "classifyClaudeError for typed error messages"
      pattern: "classifyClaudeError"
    - from: "src/app/api/decompose/route.ts"
      to: "src/lib/decompose.ts"
      via: "decomposeWorkflow returns _partial flag"
      pattern: "_partial"
    - from: "src/components/workflow-input.tsx"
      to: "src/app/api/decompose/route.ts"
      via: "fetch with ReadableStream reader consuming SSE events"
      pattern: "getReader"
    - from: "src/app/page.tsx"
      to: "src/lib/store.ts"
      via: "progressMessage from store drives loading message display"
      pattern: "progressMessage"
---

<objective>
Convert the decompose endpoint to SSE streaming with server-driven progress events, update the client to consume SSE, and replace time-based loading messages with real progress (AIRE-03). Also wire typed error classification from claude.ts into route error handling (completing AIRE-01 client-facing behavior).

Purpose: Users currently see time-based guess messages ("Analyzing workflow structure...") that don't reflect real progress. The 120s client fetchWithTimeout can abort before server retries complete. SSE solves both: the connection stays alive during retries, and the server sends actual progress stages. Additionally, typed error classification ensures users see helpful messages (rate limit vs timeout) instead of generic failures.
Output: SSE decompose route with 5 progress stages. Client SSE consumer in workflow-input.tsx. Server-driven progress messages in page.tsx via Zustand store.
</objective>

<execution_context>
@C:/Users/Brian/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Brian/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-reliability/03-RESEARCH.md
@.planning/phases/03-ai-reliability/03-01-SUMMARY.md

@src/app/api/decompose/route.ts
@src/app/api/crawl-site/route.ts
@src/components/workflow-input.tsx
@src/lib/store.ts
@src/app/page.tsx
@src/lib/claude.ts
@src/lib/decompose.ts
@src/lib/fetch-with-timeout.ts
@src/lib/api-errors.ts
@src/lib/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Convert decompose route to SSE with typed error handling</name>
  <files>src/app/api/decompose/route.ts</files>
  <action>
Rewrite the POST handler in src/app/api/decompose/route.ts to stream SSE events instead of returning a single JSON response. Follow the proven SSE pattern from src/app/api/crawl-site/route.ts.

IMPORTANT: This route currently uses `withApiHandler` HOF which returns NextResponse.json. The SSE approach requires returning a raw Response with ReadableStream. You must REMOVE the withApiHandler wrapper and handle validation/auth/rate-limiting manually (same as crawl-site does). Use the HYBRID pattern: pre-stream errors return structured JSON; in-stream errors use SSE error events.

1. Add Vercel function duration config at the top:
```typescript
export const maxDuration = 120; // Allow up to 2 minutes for decompose SSE
```

2. Define SSE event types:
```typescript
type DecomposeEvent =
  | { type: "progress"; step: string; message: string }
  | { type: "complete"; workflow: Workflow }
  | { type: "partial"; workflow: Workflow; warning: string }
  | { type: "error"; code: string; message: string };
```

3. Pre-stream validation (returns JSON errors, NOT SSE -- same as crawl-site):
   - Rate limit check (keep existing logic with rateLimit + getClientIp)
   - API key check
   - Parse and validate body with DecomposeInputSchema using safeParse (not withApiHandler)
   - Return errorResponse() for any pre-stream failures

4. SSE stream implementation:
```typescript
const encoder = new TextEncoder();
const stream = new ReadableStream({
  async start(controller) {
    const send = (event: DecomposeEvent) => {
      try {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify(event)}\n\n`));
      } catch {
        // Controller may be closed if client disconnected
      }
    };

    try {
      // Stage 1: Building context
      send({ type: "progress", step: "context", message: "Loading organizational context..." });
      // ... build org context, enrich description, build decomposeRequest (move existing code here)

      // Stage 2: Calling Claude
      send({ type: "progress", step: "analyzing", message: "Decomposing workflow with Claude..." });
      // ... call decomposeWorkflow()

      // Stage 3: Processing results
      send({ type: "progress", step: "processing", message: "Processing AI response..." });
      // ... handle _meta, version logic

      // Stage 4: Saving
      send({ type: "progress", step: "saving", message: "Saving workflow..." });
      // ... saveWorkflow()

      // Stage 5: Complete or partial
      if (result._partial) {
        send({ type: "partial", workflow, warning: result._recoveryReason || "Partial results recovered" });
      } else {
        send({ type: "complete", workflow });
      }
    } catch (error) {
      // Use classifyClaudeError for typed messages
      // Import classifyClaudeError from "@/lib/claude"
      const classified = classifyClaudeError(error);
      let userMessage: string;
      let code = "AI_ERROR";

      switch (classified.type) {
        case "rate_limit":
          userMessage = "AI service is busy. Please try again in a moment.";
          code = "RATE_LIMITED";
          break;
        case "timeout":
          userMessage = "Request timed out after multiple retries. Try a shorter workflow description.";
          break;
        case "connection":
          userMessage = "Could not reach AI service. Check your connection and try again.";
          break;
        case "api_error":
          userMessage = "AI service error. Please try again.";
          break;
        default:
          userMessage = "Decomposition failed. Please try again.";
          break;
      }

      console.error("Decompose SSE error:", error);
      send({ type: "error", code, message: userMessage });
    } finally {
      try { controller.close(); } catch { /* already closed */ }
    }
  },
});

return new Response(stream, {
  headers: {
    "Content-Type": "text/event-stream",
    "Cache-Control": "no-cache, no-transform",
    "Connection": "keep-alive",
  },
});
```

5. Move ALL existing business logic (team context enrichment, decomposeRequest building, version computation, workflow construction, saveWorkflow) into the stream's start() function, between the appropriate progress events. Keep the logic identical -- just wrap it with progress sends.

6. Import `classifyClaudeError` from `@/lib/claude` (created in Plan 01).

7. Remove the `withApiHandler` import and wrapper. Import `errorResponse` from `@/lib/api-errors` for pre-stream errors. Import `DecomposeInputSchema` from `@/lib/validation` for manual validation.

8. The workflow object sent via SSE should include `_partial` and `_recoveryReason` if applicable, so the client knows whether to show a warning. Add these to the Workflow object before sending. If Workflow type in types.ts doesn't have these fields, add them as optional:
```typescript
// In the workflow construction, if result._partial:
const workflow: Workflow & { _partial?: boolean; _recoveryReason?: string } = {
  ...existingFields,
  ...(result._partial ? { _partial: true, _recoveryReason: result._recoveryReason } : {}),
};
```
  </action>
  <verify>
1. Run `npx tsc --noEmit` -- no TypeScript errors.
2. Grep for `text/event-stream` in decompose/route.ts -- confirms SSE response.
3. Grep for `classifyClaudeError` in decompose/route.ts -- confirms typed error handling.
4. Grep for `withApiHandler` in decompose/route.ts -- should NOT be found (removed).
5. Grep for `maxDuration` in decompose/route.ts -- should be 120.
6. Run `npm run build` to confirm the route compiles in Next.js.
  </verify>
  <done>
Decompose endpoint streams SSE events with 5 progress stages (context, analyzing, processing, saving, complete/partial). Pre-stream validation returns JSON errors. In-stream errors use typed classification (rate limit, timeout, connection, api_error). Partial results sent as "partial" event type with warning. withApiHandler removed in favor of manual validation matching crawl-site pattern.
  </done>
</task>

<task type="auto">
  <name>Task 2: Client SSE consumer and server-driven progress UI</name>
  <files>src/components/workflow-input.tsx, src/lib/store.ts, src/app/page.tsx</files>
  <action>
Update the client to consume SSE events from the decompose endpoint and display server-driven progress messages.

**Step 1: Update Zustand store (src/lib/store.ts)**

Add a `progressMessage` field to the store:
```typescript
// In AppState interface, add:
progressMessage: string | null;
setProgressMessage: (msg: string | null) => void;

// In create<AppState>, add:
progressMessage: null,
setProgressMessage: (msg) => set({ progressMessage: msg }),
```

**Step 2: Update workflow-input.tsx to consume SSE**

Replace the current `fetchWithTimeout` + JSON response pattern with a streaming SSE reader:

```typescript
// In handleSubmit, replace the fetchWithTimeout block with:

const res = await fetch("/api/decompose", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    description,
    stages: inputMode === "structured" ? stages : undefined,
    ...(reanalyzeParentId ? { parentId: reanalyzeParentId } : {}),
    ...(costContext.hourlyRate || costContext.hoursPerStep || costContext.teamSize || costContext.teamContext
      ? { costContext }
      : {}),
  }),
});

// Check for pre-stream errors (non-SSE JSON responses)
const contentType = res.headers.get("content-type") || "";
if (!contentType.includes("text/event-stream")) {
  // Pre-stream error -- parse as JSON
  if (!res.ok) {
    const err = await res.json();
    throw new Error(err.error?.message || err.error || "Decomposition failed");
  }
  // Unexpected non-SSE success -- shouldn't happen but handle gracefully
  const workflow = await res.json();
  saveWorkflowLocal(workflow);
  router.push(`/xray/${workflow.id}`);
  return;
}

// SSE stream consumption
const reader = res.body!.getReader();
const decoder = new TextDecoder();
let buffer = "";

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  buffer += decoder.decode(value, { stream: true });

  // Parse SSE events from buffer (split on double newline)
  const parts = buffer.split("\n\n");
  buffer = parts.pop() || ""; // Last part may be incomplete

  for (const part of parts) {
    const line = part.trim();
    if (!line.startsWith("data: ")) continue;
    try {
      const event = JSON.parse(line.slice(6));

      if (event.type === "progress") {
        setProgressMessage(event.message);
      } else if (event.type === "complete") {
        saveWorkflowLocal(event.workflow);
        router.push(`/xray/${event.workflow.id}`);
      } else if (event.type === "partial") {
        saveWorkflowLocal(event.workflow);
        // Navigate with partial flag so xray page can show warning
        router.push(`/xray/${event.workflow.id}?partial=true`);
      } else if (event.type === "error") {
        throw new Error(event.message);
      }
    } catch (parseErr) {
      // If it's a thrown Error from the error event, re-throw
      if (parseErr instanceof Error && parseErr.message !== "Unexpected end of JSON input") {
        throw parseErr;
      }
      // Otherwise skip malformed SSE line
    }
  }
}
```

Important details:
- Remove the `fetchWithTimeout` import -- no longer needed for decompose (still used elsewhere).
- Destructure `setProgressMessage` from `useStore()` alongside the existing destructured values.
- In the `finally` block, add `setProgressMessage(null)` to clean up progress state.
- Keep the `submitLock` pattern -- it still prevents double-click.
- The 120s fetchWithTimeout is no longer needed because SSE keeps the connection alive. Regular `fetch` is used instead.

**Step 3: Update page.tsx to use server-driven progress**

In the HomeContent component in src/app/page.tsx:

1. Get `progressMessage` from the store:
```typescript
const { error, isDecomposing, setError, progressMessage } = useStore();
```

2. Update the `loadingMessage` useMemo to prefer server-driven messages. The existing time-based messages become the FALLBACK for when no server message has arrived yet (covers the initial fetch before first SSE event):
```typescript
const loadingMessage = useMemo(() => {
  if (progressMessage) return progressMessage;
  // Fallback: time-based messages for the brief period before first SSE event arrives
  if (elapsed < 5) return "Connecting to analysis engine...";
  if (elapsed < 15) return "Waiting for server response...";
  return "Still connecting...";
}, [progressMessage, elapsed]);
```

3. Update the `loadingSubtext` to show elapsed time only as secondary info:
```typescript
const loadingSubtext = useMemo(() => {
  if (elapsed < 3) return "";
  return `${elapsed}s elapsed`;
}, [elapsed]);
```

4. Keep the elapsed timer -- it still provides useful "Xs elapsed" context. But it is no longer the primary message driver.
  </action>
  <verify>
1. Run `npx tsc --noEmit` -- no TypeScript errors across all modified files.
2. Run `npm run build` -- Next.js builds successfully.
3. Grep for `getReader` in workflow-input.tsx -- confirms SSE consumption.
4. Grep for `progressMessage` in store.ts -- confirms new state field.
5. Grep for `progressMessage` in page.tsx -- confirms server-driven progress display.
6. Grep for `fetchWithTimeout` in workflow-input.tsx -- should NOT be found (replaced with regular fetch for this endpoint).
  </verify>
  <done>
Client consumes SSE events from decompose endpoint. Progress messages update in real-time via Zustand store. Loading indicator shows server-driven messages ("Loading organizational context...", "Decomposing workflow with Claude...", etc.) with elapsed time as secondary info. Partial results navigate to xray page with ?partial=true. Pre-stream errors handled as JSON. SSE connection keeps alive through retries (no more client timeout abort).
  </done>
</task>

</tasks>

<verification>
1. Full build: `npm run build` completes without errors
2. TypeScript: `npx tsc --noEmit` passes
3. SSE endpoint: decompose route returns text/event-stream with progress events
4. Typed errors: classifyClaudeError used for user-facing error messages
5. Client SSE: workflow-input.tsx reads SSE stream with getReader
6. Progress UI: page.tsx displays server-driven progress messages from store
7. Partial results: partial recovery navigates to xray page with warning flag
</verification>

<success_criteria>
- User sees "Loading organizational context...", "Decomposing workflow with Claude...", "Processing AI response...", "Saving workflow..." as real progress stages
- Rate limit errors show "AI service is busy" instead of generic "Decomposition failed"
- Timeout errors show "Request timed out after multiple retries" with helpful guidance
- Partial results navigate to xray page with partial=true query param
- No client-side timeout abort during server retries (SSE connection stays alive)
- Existing decompose functionality unchanged for normal successful responses
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-reliability/03-02-SUMMARY.md`
</output>
